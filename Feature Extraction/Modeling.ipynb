{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7387ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, welch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00d776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_video = \"../BVPs\"\n",
    "\n",
    "failed_masks = [\n",
    "    [2, \"Q1_1\"],\n",
    "    [52, \"Q7_2\"],\n",
    "    [53, \"Q4_2\"]\n",
    "]\n",
    "\n",
    "class Timestamps:\n",
    "    Q1_1 = [[9, 14],[14, 19]]\n",
    "    Q1_2 = [[24, 29]]\n",
    "\n",
    "    Q2_1 = [[1, 6],[6, 11]]\n",
    "    Q2_2 = [[7, 12], [12, 17]]\n",
    "\n",
    "    Q3_1 = [[14, 19], [19, 24]]\n",
    "    Q3_2 = [[34, 39], [40, 44], [45, 49]]\n",
    "\n",
    "    Q4_1 = [[9, 14], [16, 21]]\n",
    "    Q4_2 = [[10, 15], [16, 21]]\n",
    "\n",
    "    Q5_1 = [[18, 23], [10, 15]]\n",
    "    Q5_2 = [[13, 18], [5, 10]]\n",
    "\n",
    "    Q6_1 = [[80, 85], [85, 90]]\n",
    "    Q6_2 = [[10, 15], [18, 23]]\n",
    "\n",
    "    Q7_1 = [[43, 48], [30, 35]]\n",
    "    Q7_2 = [[36, 41], [41, 46]]\n",
    "\n",
    "    Q8_1 = [[12, 17], [17, 22]]\n",
    "    Q8_2 = [[7, 12], [12, 17]]\n",
    "\n",
    "    Q9_1 = [[15, 20], [25, 30]]\n",
    "    Q9_2 = [[13, 18], [19, 24]]\n",
    "\n",
    "paths = [\n",
    "    \"Q1_1\",\n",
    "    \"Q1_2\",\n",
    "    # \"Q2_1\",\n",
    "    # \"Q2_2\",\n",
    "    \"Q3_1\",\n",
    "    \"Q3_2\",\n",
    "    # \"Q4_1\",\n",
    "    # \"Q4_2\",\n",
    "    #\"Q5_1\",\n",
    "    #\"Q5_2\",\n",
    "    # \"Q6_1\",\n",
    "    # \"Q6_2\",\n",
    "    \"Q7_1\",\n",
    "    \"Q7_2\",\n",
    "    # \"Q8_1\",\n",
    "    # \"Q8_2\",\n",
    "    \"Q9_1\",\n",
    "    \"Q9_2\"\n",
    "]\n",
    "\n",
    "patients = list(range(1, 62))\n",
    "patients.remove(23)\n",
    "\n",
    "#patients = expressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2092cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BVP:\n",
    "    def __init__(self, patient, path, signal, features, id):\n",
    "        self.patient = patient\n",
    "        self.path = path\n",
    "        self.signal = signal\n",
    "        self.features = features\n",
    "        self.id = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abfa94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_bvp(bvp, t_start, t_end, fs = 60):\n",
    "\n",
    "    n_start = int(t_start * fs)\n",
    "    n_end   = int(t_end * fs) if t_end is not None else len(bvp)\n",
    "    return bvp[n_start:n_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773a4b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Patient_2, Q1_1\n",
      "Skipping Patient_52, Q7_2\n",
      "Loaded 956 BVP signals\n"
     ]
    }
   ],
   "source": [
    "fs = 60\n",
    "\n",
    "BVPs = []\n",
    "\n",
    "for patient in patients:\n",
    "\n",
    "    for path in paths:\n",
    "\n",
    "        if [patient, path] in failed_masks:\n",
    "            print(f\"Skipping Patient_{patient}, {path}\")\n",
    "            continue\n",
    "\n",
    "        data = np.load(f\"{base_path_video}/Patient_{patient}/{path}.npy\")\n",
    "\n",
    "        for t_start, t_end in getattr(Timestamps, path):\n",
    "\n",
    "            data_cut = cut_bvp(data, t_start, t_end, fs)\n",
    "\n",
    "            id = f\"{patient}{path}\"\n",
    "\n",
    "            bvp = BVP(patient, path, data_cut, [], id)\n",
    "\n",
    "            BVPs.append(bvp)\n",
    "\n",
    "            #print(f\"Patient_{patient}, {path}: {data.shape}\")\n",
    "\n",
    "print(f\"Loaded {len(BVPs)} BVP signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187cc995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(BVPs[0].signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a0fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks, czt\n",
    "from scipy.stats import linregress, skew, kurtosis\n",
    "from itertools import permutations\n",
    "\n",
    "\n",
    "def compute_bvp_short_window_features(\n",
    "    bvp,\n",
    "    fs,\n",
    "    fmin=0.66,\n",
    "    fmax=3.0,\n",
    "    n_czt_bins=512\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust short-window (≈3s) BVP features for arousal classification.\n",
    "    Designed for small manually labeled emotional segments.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bvp : np.ndarray\n",
    "        1D BVP signal\n",
    "    fs : float\n",
    "        Sampling frequency (Hz)\n",
    "    \"\"\"\n",
    "\n",
    "    features = {}\n",
    "    bvp = np.asarray(bvp, dtype=float)\n",
    "\n",
    "    if len(bvp) < fs * 2:  # too short\n",
    "        return {k: np.nan for k in [\n",
    "            \"mean_hr\", \"hr_slope\",\n",
    "            \"dom_freq\", \"peak_power_ratio\",\n",
    "            \"spec_entropy\", \"freq_variance\", \"hr_snr\",\n",
    "            \"amp_mean\", \"amp_std\",\n",
    "            \"signal_energy\", \"signal_std\",\n",
    "            \"skewness\", \"kurtosis\",\n",
    "            \"sample_entropy\", \"perm_entropy\",\n",
    "            \"peak_success_ratio\"\n",
    "        ]}\n",
    "\n",
    "    # Remove DC\n",
    "    bvp = bvp - np.mean(bvp)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Peak detection\n",
    "    # --------------------------------------------------\n",
    "    min_dist = int(0.4 * fs)\n",
    "    peaks, _ = find_peaks(bvp, distance=min_dist)\n",
    "\n",
    "    if len(peaks) >= 2:\n",
    "        ibi = np.diff(peaks) / fs\n",
    "        hr = 60.0 / ibi\n",
    "        features[\"mean_hr\"] = np.mean(hr)\n",
    "\n",
    "        t = np.arange(len(hr))\n",
    "        features[\"hr_slope\"] = linregress(t, hr).slope\n",
    "    else:\n",
    "        features[\"mean_hr\"] = np.nan\n",
    "        features[\"hr_slope\"] = np.nan\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. Spectral features (CZT)\n",
    "    # --------------------------------------------------\n",
    "    w = np.exp(-1j * 2 * np.pi * (fmax - fmin) / (n_czt_bins * fs))\n",
    "    a = np.exp(1j * 2 * np.pi * fmin / fs)\n",
    "\n",
    "    spectrum = czt(bvp, n_czt_bins, w, a)\n",
    "    power = np.abs(spectrum) ** 2\n",
    "    freqs = np.linspace(fmin, fmax, n_czt_bins)\n",
    "\n",
    "    total_power = np.sum(power)\n",
    "\n",
    "    if total_power > 0:\n",
    "        idx_peak = np.argmax(power)\n",
    "        dom_freq = freqs[idx_peak]\n",
    "\n",
    "        features[\"dom_freq\"] = dom_freq\n",
    "        features[\"peak_power_ratio\"] = power[idx_peak] / total_power\n",
    "\n",
    "        p_norm = power / total_power\n",
    "        features[\"spec_entropy\"] = -np.sum(\n",
    "            p_norm * np.log2(p_norm + 1e-12)\n",
    "        )\n",
    "\n",
    "        features[\"freq_variance\"] = np.sum(\n",
    "            power * (freqs - dom_freq) ** 2\n",
    "        ) / total_power\n",
    "\n",
    "        features[\"hr_snr\"] = np.max(power) / (np.mean(power) + 1e-12)\n",
    "\n",
    "    else:\n",
    "        features[\"dom_freq\"] = np.nan\n",
    "        features[\"peak_power_ratio\"] = np.nan\n",
    "        features[\"spec_entropy\"] = np.nan\n",
    "        features[\"freq_variance\"] = np.nan\n",
    "        features[\"hr_snr\"] = np.nan\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Pulse amplitude features\n",
    "    # --------------------------------------------------\n",
    "    troughs, _ = find_peaks(-bvp, distance=min_dist)\n",
    "    n_beats = min(len(peaks), len(troughs))\n",
    "\n",
    "    if n_beats > 0:\n",
    "        amp = bvp[peaks[:n_beats]] - bvp[troughs[:n_beats]]\n",
    "        features[\"amp_mean\"] = np.mean(amp)\n",
    "        features[\"amp_std\"] = np.std(amp)\n",
    "    else:\n",
    "        features[\"amp_mean\"] = np.nan\n",
    "        features[\"amp_std\"] = np.nan\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 4. Signal statistics\n",
    "    # --------------------------------------------------\n",
    "    features[\"signal_energy\"] = np.sum(bvp ** 2)\n",
    "    features[\"signal_std\"] = np.std(bvp)\n",
    "    features[\"skewness\"] = skew(bvp)\n",
    "    features[\"kurtosis\"] = kurtosis(bvp)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 5. Entropy features\n",
    "    # --------------------------------------------------\n",
    "    def sample_entropy(x, m=2, r=0.2):\n",
    "        x = np.asarray(x)\n",
    "        r *= np.std(x)\n",
    "        N = len(x)\n",
    "\n",
    "        if N < m + 2:\n",
    "            return np.nan\n",
    "\n",
    "        def _phi(m):\n",
    "            x_m = np.array([x[i:i + m] for i in range(N - m)])\n",
    "            C = np.sum(\n",
    "                np.max(\n",
    "                    np.abs(x_m[:, None] - x_m[None, :]), axis=2\n",
    "                ) <= r,\n",
    "                axis=0\n",
    "            ) - 1\n",
    "            return np.sum(C) / ((N - m) * (N - m - 1))\n",
    "\n",
    "        return -np.log(_phi(m + 1) / _phi(m))\n",
    "\n",
    "    try:\n",
    "        features[\"sample_entropy\"] = sample_entropy(bvp)\n",
    "    except Exception:\n",
    "        features[\"sample_entropy\"] = np.nan\n",
    "\n",
    "    def permutation_entropy(x, order=3, delay=1):\n",
    "        x = np.asarray(x)\n",
    "        perms = list(permutations(range(order)))\n",
    "        counts = np.zeros(len(perms))\n",
    "\n",
    "        for i in range(len(x) - delay * (order - 1)):\n",
    "            pattern = x[i:i + delay * order:delay]\n",
    "            idx = perms.index(tuple(np.argsort(pattern)))\n",
    "            counts[idx] += 1\n",
    "\n",
    "        p = counts / np.sum(counts)\n",
    "        return -np.sum(p * np.log2(p + 1e-12))\n",
    "\n",
    "    try:\n",
    "        features[\"perm_entropy\"] = permutation_entropy(bvp)\n",
    "    except Exception:\n",
    "        features[\"perm_entropy\"] = np.nan\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 6. Signal quality\n",
    "    # --------------------------------------------------\n",
    "    if not np.isnan(features[\"mean_hr\"]):\n",
    "        expected_beats = len(bvp) / fs * (features[\"mean_hr\"] / 60.0)\n",
    "        features[\"peak_success_ratio\"] = (\n",
    "            len(peaks) / expected_beats\n",
    "            if expected_beats > 0 else np.nan\n",
    "        )\n",
    "    else:\n",
    "        features[\"peak_success_ratio\"] = np.nan\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6639fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 1 videos\n",
      "16 Feats: {'mean_hr': np.float64(111.44981065285458), 'hr_slope': np.float64(-10.533509727906129), 'dom_freq': np.float64(1.1179256360078278), 'peak_power_ratio': np.float64(0.014472147296813044), 'spec_entropy': np.float64(7.76061405476444), 'freq_variance': np.float64(0.3761858775543272), 'hr_snr': np.float64(7.409739415968071), 'amp_mean': np.float64(0.26862234354099823), 'amp_std': np.float64(0.08823250705071595), 'signal_energy': np.float64(2.942719042171681), 'signal_std': np.float64(0.09904071624289479), 'skewness': np.float64(0.479878882144499), 'kurtosis': np.float64(-0.44220686560316524), 'sample_entropy': np.float64(0.4270695671693521), 'perm_entropy': np.float64(1.4099888308980844), 'peak_success_ratio': np.float64(0.861374276345988)}\n"
     ]
    }
   ],
   "source": [
    "fs = 60\n",
    "\n",
    "valid = []\n",
    "\n",
    "failed = []\n",
    "\n",
    "failed_masks = [\n",
    "    [2, \"Q1_1\"],\n",
    "    [52, \"Q7_2\"],\n",
    "    [53, \"Q4_2\"]\n",
    "]\n",
    "\n",
    "bvp = BVPs[0]\n",
    "try:\n",
    "    \n",
    "    feats = compute_bvp_short_window_features(bvp.signal, fs)\n",
    "\n",
    "    if feats is None or []:\n",
    "        # Do nothing\n",
    "        print(f\"Failed: Patient_{bvp.patient}, {bvp.path}\")\n",
    "        BVPs.remove(bvp)\n",
    "\n",
    "    else:\n",
    "\n",
    "        bvp.features = feats\n",
    "\n",
    "        valid.append(f\"Patient_{bvp.patient}, {bvp.path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(f\"Extracted features for {len(valid)} videos\")\n",
    "\n",
    "print(f\"{len(feats)} Feats: {feats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480b50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 956 videos...\n",
      "Failed: []\n"
     ]
    }
   ],
   "source": [
    "fs = 60  # sampling rate\n",
    "\n",
    "valid = []\n",
    "failed = []\n",
    "\n",
    "for bvp in BVPs:  # use a copy to safely remove items\n",
    "\n",
    "    print(f\"Computing Features for Patient_{bvp.patient}...\", end=\"\\r\", flush=True)\n",
    "    \n",
    "    try:\n",
    "        # Use the new windowed feature extraction\n",
    "        feats = compute_bvp_short_window_features(bvp.signal, fs)\n",
    "\n",
    "        if feats is None or feats == []:\n",
    "            print(f\"Failed: Patient_{bvp.patient}, {bvp.path}\")\n",
    "            failed.append(f\"Patient_{bvp.patient}, {bvp.path}\")\n",
    "            BVPs.remove(bvp)  # remove problematic signal\n",
    "        else:\n",
    "            bvp.features = feats\n",
    "            valid.append(f\"Patient_{bvp.patient}, {bvp.path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for Patient_{bvp.patient}, {bvp.path}: {e}\")\n",
    "        failed.append(f\"Patient_{bvp.patient}, {bvp.path}\")\n",
    "        BVPs.remove(bvp)\n",
    "\n",
    "print(f\"Extracted features for {len(valid)} videos\")\n",
    "print(f\"Failed: {failed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648d43db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of features:  dict_keys(['mean_hr', 'hr_slope', 'dom_freq', 'peak_power_ratio', 'spec_entropy', 'freq_variance', 'hr_snr', 'amp_mean', 'amp_std', 'signal_energy', 'signal_std', 'skewness', 'kurtosis', 'sample_entropy', 'perm_entropy', 'peak_success_ratio'])\n",
      "Features per video:  16\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of features: \", BVPs[0].features.keys())\n",
    "print(\"Features per video: \", len(BVPs[0].features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed02870",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"Q1\": \"Q1: ↑Arousal ↓Val\",\n",
    "    \"Q2\": \"Q2: ↑Arousal -Val\",\n",
    "    \"Q3\": \"Q3: ↑Arousal ↑Val\",\n",
    "    \"Q4\": \"Q4: -Arousal ↓Val\",\n",
    "    \"Q5\": \"Q5: -Arousal -Val\",\n",
    "    \"Q6\": \"Q6: -Arousal ↑Val\",\n",
    "    \"Q7\": \"Q7: ↓Arousal ↓Val\",\n",
    "    \"Q8\": \"Q8: ↓Arousal -Val\",\n",
    "    \"Q9\": \"Q9: ↓Arousal ↑Val\",\n",
    "}\n",
    "\n",
    "def get_label(path):\n",
    "    q = path.split(\"_\")[0]  # \"Q3_2\" → \"Q3\"\n",
    "    return label_map[q]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418b900",
   "metadata": {},
   "source": [
    "LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "675309ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Split\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y,\n",
    "#     test_size=0.3,\n",
    "#     stratify=y,\n",
    "# )\n",
    "\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_test.shape, y_test.shape)\n",
    "\n",
    "# print(\"Example of data: \", X_train[0], y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f02bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ca622da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(956, 16) (956,)\n",
      "(array(['Q1: ↑Arousal ↓Val', 'Q3: ↑Arousal ↑Val', 'Q7: ↓Arousal ↓Val',\n",
      "       'Q9: ↓Arousal ↑Val'], dtype='<U17'), array([178, 300, 238, 240]))\n",
      "Example of data:  [ 1.11449811e+02 -1.05335097e+01  1.11792564e+00  1.44721473e-02\n",
      "  7.76061405e+00  3.76185878e-01  7.40973942e+00  2.68622344e-01\n",
      "  8.82325071e-02  2.94271904e+00  9.90407162e-02  4.79878882e-01\n",
      " -4.42206866e-01  4.27069567e-01  1.40998883e+00  8.61374276e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "groups = []\n",
    "\n",
    "for bvp in BVPs:\n",
    "    if bvp is None or bvp.features is []:\n",
    "        print(\"Error: Patient\", bvp.patient, bvp.path)\n",
    "        continue\n",
    "\n",
    "    feat_values = list(bvp.features.values())\n",
    "    X.append(feat_values)\n",
    "    y.append(get_label(bvp.path))\n",
    "    groups.append(bvp.id)  \n",
    "    \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(np.unique(y, return_counts=True))\n",
    "print(\"Example of data: \", X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff0f106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Score: 0.3489583333333333\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Q1: ↑Arousal ↓Val       0.36      0.14      0.20        36\n",
      "Q3: ↑Arousal ↑Val       0.48      0.70      0.57        60\n",
      "Q7: ↓Arousal ↓Val       0.24      0.25      0.25        48\n",
      "Q9: ↓Arousal ↑Val       0.20      0.17      0.18        48\n",
      "\n",
      "         accuracy                           0.35       192\n",
      "        macro avg       0.32      0.31      0.30       192\n",
      "     weighted avg       0.33      0.35      0.32       192\n",
      "\n",
      "[[ 5 12 13  6]\n",
      " [ 2 42  7  9]\n",
      " [ 3 15 12 18]\n",
      " [ 4 19 17  8]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 1\n",
      "Score: 0.3645833333333333\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Q1: ↑Arousal ↓Val       0.50      0.22      0.31        36\n",
      "Q3: ↑Arousal ↑Val       0.42      0.53      0.47        60\n",
      "Q7: ↓Arousal ↓Val       0.32      0.40      0.35        48\n",
      "Q9: ↓Arousal ↑Val       0.28      0.23      0.25        48\n",
      "\n",
      "         accuracy                           0.36       192\n",
      "        macro avg       0.38      0.35      0.35       192\n",
      "     weighted avg       0.37      0.36      0.36       192\n",
      "\n",
      "[[ 8 11 10  7]\n",
      " [ 5 32 16  7]\n",
      " [ 0 14 19 15]\n",
      " [ 3 19 15 11]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 2\n",
      "Score: 0.2894736842105263\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Q1: ↑Arousal ↓Val       0.08      0.03      0.04        36\n",
      "Q3: ↑Arousal ↑Val       0.42      0.52      0.46        60\n",
      "Q7: ↓Arousal ↓Val       0.18      0.22      0.19        46\n",
      "Q9: ↓Arousal ↑Val       0.28      0.27      0.28        48\n",
      "\n",
      "         accuracy                           0.29       190\n",
      "        macro avg       0.24      0.26      0.24       190\n",
      "     weighted avg       0.26      0.29      0.27       190\n",
      "\n",
      "[[ 1 13 15  7]\n",
      " [ 3 31 16 10]\n",
      " [ 6 14 10 16]\n",
      " [ 3 16 16 13]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 3\n",
      "Score: 0.34554973821989526\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Q1: ↑Arousal ↓Val       0.40      0.23      0.29        35\n",
      "Q3: ↑Arousal ↑Val       0.43      0.52      0.47        60\n",
      "Q7: ↓Arousal ↓Val       0.35      0.29      0.32        48\n",
      "Q9: ↓Arousal ↑Val       0.22      0.27      0.24        48\n",
      "\n",
      "         accuracy                           0.35       191\n",
      "        macro avg       0.35      0.33      0.33       191\n",
      "     weighted avg       0.35      0.35      0.34       191\n",
      "\n",
      "[[ 8  9  4 14]\n",
      " [ 4 31 10 15]\n",
      " [ 6 11 14 17]\n",
      " [ 2 21 12 13]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Fold 4\n",
      "Score: 0.36649214659685864\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Q1: ↑Arousal ↓Val       0.35      0.17      0.23        35\n",
      "Q3: ↑Arousal ↑Val       0.51      0.62      0.56        60\n",
      "Q7: ↓Arousal ↓Val       0.25      0.33      0.29        48\n",
      "Q9: ↓Arousal ↑Val       0.29      0.23      0.26        48\n",
      "\n",
      "         accuracy                           0.37       191\n",
      "        macro avg       0.35      0.34      0.33       191\n",
      "     weighted avg       0.36      0.37      0.35       191\n",
      "\n",
      "[[ 6 11 11  7]\n",
      " [ 1 37 13  9]\n",
      " [ 8 13 16 11]\n",
      " [ 2 11 24 11]]\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, groups)):\n",
    "    print(f\"Fold {fold}\")\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    score = pipe.score(X_test, y_test)\n",
    "\n",
    "    print(\"Score:\", score)\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"-\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de1920d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipe_5s.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(pipe, \"pipe_5s.joblib\")\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# pipe = joblib.load(\"bvp_emotion_pipeline.joblib\")\n",
    "\n",
    "# pipe.predict(X)\n",
    "# pipe.predict_proba(X)\n",
    "# pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ab7ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               feature  importance\n",
      "4         spec_entropy    0.072606\n",
      "3     peak_power_ratio    0.071037\n",
      "1             hr_slope    0.066742\n",
      "11            skewness    0.066288\n",
      "6               hr_snr    0.066081\n",
      "12            kurtosis    0.065698\n",
      "13      sample_entropy    0.064353\n",
      "8              amp_std    0.063014\n",
      "5        freq_variance    0.062587\n",
      "14        perm_entropy    0.060540\n",
      "15  peak_success_ratio    0.059552\n",
      "0              mean_hr    0.059460\n",
      "2             dom_freq    0.058691\n",
      "7             amp_mean    0.058336\n",
      "9        signal_energy    0.053684\n",
      "10          signal_std    0.051331\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# feature names from BVP objects (windowed)\n",
    "feature_names = list(BVPs[0].features.keys())\n",
    "\n",
    "# extract RF importances from pipeline\n",
    "importances = pipe.named_steps['clf'].feature_importances_\n",
    "\n",
    "# build DataFrame\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(imp_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
